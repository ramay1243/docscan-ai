#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö URL —Å—Ç—Ä–∞–Ω–∏—Ü —Å–∞–π—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–æ–±—Ö–æ–¥–∞ –≤ –Ø–Ω–¥–µ–∫—Å–µ"""

import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from app import app
    from models.sqlite_users import Article, FullNews, Question, db
    
    base_url = "https://docscan-ai.ru"
    
    # –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    static_pages = [
        '/',
        '/news',
        '/analiz-dokumentov',
        '/proverka-dogovorov',
        '/articles',
        '/questions',
        '/questions/ask',
        '/faq',
        '/calculator-penalty',
        '/mobile-app',
        '/proverka-dokumentov-onlayn',
        '/articles/nalogovaya-proverka',
        '/partners',
        '/tariffs',
        '/articles/about',
        '/articles/guide',
        '/articles/tech',
        '/articles/rent',
        '/articles/labor',
        '/articles/tax',
        '/articles/business-protection',
        '/articles/freelance-gph',
        '/articles/ipoteka-2025',
        '/articles/lizing',
        '/articles/strahovanie',
        '/articles/okazanie-uslug',
        '/riski-dogovora-zayma',
        '/avtokredit-skrytye-usloviya',
        '/ii-dlya-proverki-dogovorov-onlayn-besplatno',
        '/medicinskie-dokumenty-analiz',
        '/contact',
        '/terms',
        '/privacy',
        '/offer',
        '/api',
        '/chat',
    ]
    
    with app.app_context():
        all_urls = []
        
        # –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        print("üìÑ –°–¢–ê–¢–ò–ß–ï–°–ö–ò–ï –°–¢–†–ê–ù–ò–¶–´:")
        print("-" * 80)
        for page in static_pages:
            url = f"{base_url}{page}"
            print(url)
            all_urls.append(url)
        print()
        
        # –°—Ç–∞—Ç—å–∏ –∏–∑ –ë–î
        print("üìù –°–¢–ê–¢–¨–ò –ò–ó –ë–ê–ó–´ –î–ê–ù–ù–´–•:")
        print("-" * 80)
        try:
            articles = Article.query.filter_by(status='published').all()
            if articles:
                for article in articles:
                    url = f"{base_url}/articles/{article.slug}"
                    print(url)
                    all_urls.append(url)
            else:
                print("(–ù–µ—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π)")
        except Exception as e:
            print(f"(–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–µ–π: {e})")
        print()
        
        # –ù–æ–≤–æ—Å—Ç–∏ –∏–∑ –ë–î
        print("üì∞ –ù–û–í–û–°–¢–ò –ò–ó –ë–ê–ó–´ –î–ê–ù–ù–´–•:")
        print("-" * 80)
        try:
            news = FullNews.query.filter_by(is_published=True).all()
            if news:
                for n in news:
                    url = f"{base_url}/news/{n.slug}"
                    print(url)
                    all_urls.append(url)
            else:
                print("(–ù–µ—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π)")
        except Exception as e:
            print(f"(–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π: {e})")
        print()
        
        # –í–æ–ø—Ä–æ—Å—ã –∏–∑ –ë–î
        print("‚ùì –í–û–ü–†–û–°–´ –ò–ó –ë–ê–ó–´ –î–ê–ù–ù–´–•:")
        print("-" * 80)
        try:
            questions = Question.query.all()
            if questions:
                for q in questions:
                    url = f"{base_url}/questions/{q.id}"
                    print(url)
                    all_urls.append(url)
            else:
                print("(–ù–µ—Ç –≤–æ–ø—Ä–æ—Å–æ–≤)")
        except Exception as e:
            print(f"(–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤: {e})")
        print()
        
        # –ò—Ç–æ–≥–æ
        print("=" * 80)
        print(f"–ò–¢–û–ì–û –°–¢–†–ê–ù–ò–¶: {len(all_urls)}")
        print(f"  - –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ: {len(static_pages)}")
        print(f"  - –°—Ç–∞—Ç—å–∏: {len([a for a in all_urls if '/articles/' in a and a not in [f'{base_url}{p}' for p in static_pages]])}")
        print(f"  - –ù–æ–≤–æ—Å—Ç–∏: {len([a for a in all_urls if '/news/' in a])}")
        print(f"  - –í–æ–ø—Ä–æ—Å—ã: {len([a for a in all_urls if '/questions/' in a and '/ask' not in a])}")
        print("=" * 80)
        print()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        with open('ALL_URLS_FOR_YANDEX.txt', 'w', encoding='utf-8') as f:
            f.write("–í–°–ï URL –î–õ–Ø –ü–ï–†–ï–û–ë–•–û–î–ê –í –Ø–ù–î–ï–ö–°–ï\n")
            f.write("=" * 80 + "\n\n")
            for url in all_urls:
                f.write(url + "\n")
        
        print("‚úÖ –°–ø–∏—Å–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: ALL_URLS_FOR_YANDEX.txt")
        print()
        print("üí° –î–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ –Ø–Ω–¥–µ–∫—Å:")
        print("   1. –û—Ç–∫—Ä–æ–π—Ç–µ —Ñ–∞–π–ª ALL_URLS_FOR_YANDEX.txt")
        print("   2. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –≤—Å–µ URL")
        print("   3. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –Ø–Ω–¥–µ–∫—Å.–í–µ–±–º–∞—Å—Ç–µ—Ä: https://webmaster.yandex.ru")
        print("   4. –†–∞–∑–¥–µ–ª '–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ' -> '–ü–µ—Ä–µ–æ–±—Ö–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü'")
        print("   5. –í—Å—Ç–∞–≤—å—Ç–µ —Å–ø–∏—Å–æ–∫ URL –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–∞ –ø–µ—Ä–µ–æ–±—Ö–æ–¥")
        print()
        print("üìã –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ sitemap.xml:")
        print(f"   {base_url}/sitemap.xml")

except Exception as e:
    print(f"–û—à–∏–±–∫–∞: {e}")
    import traceback
    traceback.print_exc()

