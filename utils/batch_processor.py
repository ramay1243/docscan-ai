#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""

import os
import json
import logging
import threading
from datetime import datetime
from models.sqlite_users import db, BatchProcessingTask, BatchProcessingFile, AnalysisHistory
from services.file_processing import extract_text_from_file, validate_file
from services.analysis import analyze_text
from utils.analysis_settings_manager import AnalysisSettingsManager

logger = logging.getLogger(__name__)

class BatchProcessor:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    
    @staticmethod
    def create_batch_task(user_id, task_name=None, file_count=0):
        """–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –ø–∞–∫–µ—Ç–Ω—É—é –∑–∞–¥–∞—á—É"""
        try:
            task = BatchProcessingTask(
                user_id=user_id,
                task_name=task_name,
                status='pending',
                total_files=file_count,
                processed_files=0,
                failed_files=0,
                created_at=datetime.now().isoformat()
            )
            db.session.add(task)
            db.session.commit()
            
            logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–∫–µ—Ç–Ω–∞—è –∑–∞–¥–∞—á–∞ {task.id} –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            return task.id, None
        except Exception as e:
            db.session.rollback()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞–∫–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏: {e}")
            return None, str(e)
    
    @staticmethod
    def add_file_to_task(task_id, filename, file_path):
        """–î–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª –≤ –ø–∞–∫–µ—Ç–Ω—É—é –∑–∞–¥–∞—á—É"""
        try:
            file_record = BatchProcessingFile(
                task_id=task_id,
                filename=filename,
                file_path=file_path,
                status='pending',
                created_at=datetime.now().isoformat()
            )
            db.session.add(file_record)
            db.session.commit()
            
            return file_record.id, None
        except Exception as e:
            db.session.rollback()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –≤ –∑–∞–¥–∞—á—É: {e}")
            return None, str(e)
    
    @staticmethod
    def process_batch_task_async(task_id, user_id, app_instance):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏ (–∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ)"""
        def process_task():
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ë–î –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            with app_instance.app_context():
                try:
                    logger.info(f"üöÄ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞–∫–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏ {task_id}")
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏
                    task = BatchProcessingTask.query.get(task_id)
                    if not task:
                        logger.error(f"‚ùå –ó–∞–¥–∞—á–∞ {task_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                        return
                    
                    task.status = 'processing'
                    task.started_at = datetime.now().isoformat()
                    db.session.commit()
                
                    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –∑–∞–¥–∞—á–∏
                    files = BatchProcessingFile.query.filter_by(task_id=task_id).all()
                    
                    results = []
                    processed_count = 0
                    failed_count = 0
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    analysis_settings = None
                    try:
                        user = app_instance.user_manager.get_user(user_id)
                        if user and user.plan == 'premium':
                            analysis_settings = AnalysisSettingsManager.get_user_settings(user_id)
                            if analysis_settings and analysis_settings.get('use_default'):
                                analysis_settings = None
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞: {e}")
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
                    for file_record in files:
                        try:
                            logger.info(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {file_record.filename}")
                            
                            file_record.status = 'processing'
                            db.session.commit()
                            
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞
                            if not file_record.file_path:
                                raise Exception(f"–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –Ω–µ —É–∫–∞–∑–∞–Ω –¥–ª—è {file_record.filename}")
                            
                            if not os.path.exists(file_record.file_path):
                                raise Exception(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_record.file_path}")
                            
                            # extract_text_from_file –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª–∏–±–æ —Ç–µ–∫—Å—Ç, –ª–∏–±–æ —Å—Ç—Ä–æ–∫—É –æ—à–∏–±–∫–∏
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ç–µ–∫—Å—Ç (–Ω–µ –æ—à–∏–±–∫–∞)
                            text_result = extract_text_from_file(file_record.file_path, file_record.filename)
                            
                            # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "‚ùå" –∏–ª–∏ "–û—à–∏–±–∫–∞", —ç—Ç–æ –æ—à–∏–±–∫–∞
                            if isinstance(text_result, str) and (text_result.startswith("‚ùå") or text_result.startswith("–û—à–∏–±–∫–∞") or text_result.startswith("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è")):
                                raise Exception(text_result)
                            
                            text = text_result
                            # –î–ª—è PDF –ø—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
                            pages_count = 1
                            if file_record.filename.lower().endswith('.pdf'):
                                try:
                                    import PyPDF2
                                    with open(file_record.file_path, 'rb') as f:
                                        reader = PyPDF2.PdfReader(f)
                                        pages_count = len(reader.pages)
                                except:
                                    pass
                            
                            if not text or len(text.strip()) < 50:
                                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π")
                            
                            # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ª–∏–º–∏—Ç–æ–≤
                            user = app_instance.user_manager.get_user(user_id)
                            if not user:
                                raise Exception("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç—ã
                            if not app_instance.user_manager.can_analyze(user_id):
                                raise Exception("–î–æ—Å—Ç–∏–≥–Ω—É—Ç –¥–Ω–µ–≤–Ω–æ–π –ª–∏–º–∏—Ç –∞–Ω–∞–ª–∏–∑–æ–≤")
                            
                            # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
                            analysis_result = analyze_text(
                                text=text,
                                user_plan=user.plan if hasattr(user, 'plan') else user.get('plan', 'free'),
                                is_authenticated=True,
                                user_id=user_id,
                                analysis_settings=analysis_settings
                            )
                            
                            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
                            app_instance.user_manager.record_usage(user_id)
                            
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
                            history = AnalysisHistory(
                                user_id=user_id,
                                filename=file_record.filename,
                                document_type=analysis_result.get('document_type'),
                                document_type_name=analysis_result.get('document_type_name'),
                                risk_level=analysis_result.get('risk_level'),
                                created_at=datetime.now().isoformat(),
                                analysis_summary=analysis_result.get('summary', '')[:500]
                            )
                            db.session.add(history)
                            db.session.flush()
                            
                            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç (PDF) –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
                            report_path = None
                            try:
                                from services.pdf_generator import generate_analysis_pdf
                                
                                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±—Ä–µ–Ω–¥–∏–Ω–≥–∞
                                branding_settings = None
                                try:
                                    from models.sqlite_users import BrandingSettings
                                    branding_obj = BrandingSettings.query.filter_by(user_id=user_id).first()
                                    if branding_obj and branding_obj.is_active:
                                        branding_settings = {
                                            'is_active': True,
                                            'logo_path': branding_obj.logo_path,
                                            'primary_color': branding_obj.primary_color,
                                            'secondary_color': branding_obj.secondary_color,
                                            'company_name': branding_obj.company_name
                                        }
                                except Exception as e:
                                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±—Ä–µ–Ω–¥–∏–Ω–≥–∞: {e}")
                                
                                reports_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'static', 'reports', 'batch', f'task_{task_id}')
                                os.makedirs(reports_dir, exist_ok=True)
                                
                                safe_filename = "".join(c for c in file_record.filename if c.isalnum() or c in (' ', '-', '_', '.')).rstrip()
                                report_filename = f"{safe_filename}_report.pdf"
                                report_path_full = os.path.join(reports_dir, report_filename)
                                
                                # generate_analysis_pdf –ø—Ä–∏–Ω–∏–º–∞–µ—Ç: (analysis_data, filename="document.pdf", branding_settings=None)
                                pdf_content = generate_analysis_pdf(
                                    analysis_result,  # analysis_data
                                    file_record.filename,  # filename
                                    branding_settings  # branding_settings
                                )
                                
                                with open(report_path_full, 'wb') as f:
                                    f.write(pdf_content)
                                
                                report_path = f'static/reports/batch/task_{task_id}/{report_filename}'
                                logger.info(f"‚úÖ –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {report_path}")
                            except Exception as e:
                                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –¥–ª—è {file_record.filename}: {e}")
                            
                            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å —Ñ–∞–π–ª–∞
                            file_record.status = 'completed'
                            file_record.analysis_result_json = json.dumps(analysis_result, ensure_ascii=False)
                            file_record.analysis_history_id = history.id
                            file_record.full_report_path = report_path
                            file_record.processed_at = datetime.now().isoformat()
                            db.session.commit()
                            
                            results.append({
                                'filename': file_record.filename,
                                'status': 'completed',
                                'analysis': analysis_result
                            })
                            
                            processed_count += 1
                            task.processed_files = processed_count
                            db.session.commit()
                            
                            logger.info(f"‚úÖ –§–∞–π–ª {file_record.filename} –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ")
                            
                        except Exception as e:
                            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_record.filename}: {e}")
                            file_record.status = 'failed'
                            file_record.error_message = str(e)
                            file_record.processed_at = datetime.now().isoformat()
                            db.session.commit()
                            
                            results.append({
                                'filename': file_record.filename,
                                'status': 'failed',
                                'error': str(e)
                            })
                            
                            failed_count += 1
                            task.failed_files = failed_count
                            db.session.commit()
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    task.results_json = json.dumps(results, ensure_ascii=False)
                    task.status = 'completed'
                    task.completed_at = datetime.now().isoformat()
                    db.session.commit()
                    
                    logger.info(f"‚úÖ –ü–∞–∫–µ—Ç–Ω–∞—è –∑–∞–¥–∞—á–∞ {task_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count}, –û—à–∏–±–æ–∫: {failed_count}")
                    
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                    try:
                        BatchProcessor.generate_summary_report(task_id, results)
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç: {e}")
                    
                    # –°–æ–∑–¥–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
                    try:
                        from models.sqlite_users import Notification
                        notification = Notification(
                            user_id=user_id,
                            title=f"–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞",
                            message=f"–ó–∞–¥–∞—á–∞ '{task.task_name or f'–ó–∞–¥–∞—á–∞ #{task_id}'}' –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count} –∏–∑ {task.total_files} —Ñ–∞–π–ª–æ–≤.",
                            type='batch_completed',
                            created_at=datetime.now().isoformat()
                        )
                        db.session.add(notification)
                        db.session.commit()
                        logger.info(f"‚úÖ –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ: {e}")
                    
                except Exception as e:
                    logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞–∫–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏ {task_id}: {e}")
                    try:
                        task = BatchProcessingTask.query.get(task_id)
                        if task:
                            task.status = 'failed'
                            task.error_message = str(e)
                            task.completed_at = datetime.now().isoformat()
                            db.session.commit()
                    except Exception as db_error:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –æ—à–∏–±–∫–∏: {db_error}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        thread = threading.Thread(target=process_task)
        thread.daemon = True
        thread.start()
    
    @staticmethod
    def generate_summary_report(task_id, results):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –≤—Å–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º"""
        try:
            task = BatchProcessingTask.query.get(task_id)
            if not task:
                return
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –∑–∞–¥–∞—á–∏ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—É—Ç—è–º –æ—Ç—á–µ—Ç–æ–≤
            files = BatchProcessingFile.query.filter_by(task_id=task_id).all()
            file_reports = {f.filename: f.full_report_path for f in files if f.full_report_path}
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            total = len(results)
            completed = len([r for r in results if r.get('status') == 'completed'])
            failed = len([r for r in results if r.get('status') == 'failed'])
            success_rate = int((completed / total * 100)) if total > 0 else 0
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            doc_types = {}
            risk_levels = {'CRITICAL': 0, 'HIGH': 0, 'MEDIUM': 0, 'LOW': 0, 'INFO': 0}
            
            # –°–æ–±–∏—Ä–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–∏—Å–∫–∏
            all_issues = []
            critical_files = []
            high_risk_files = []
            
            for result in results:
                if result.get('status') == 'completed' and result.get('analysis'):
                    analysis = result['analysis']
                    doc_type = analysis.get('document_type_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                    doc_types[doc_type] = doc_types.get(doc_type, 0) + 1
                    
                    risk = analysis.get('risk_level', 'INFO')
                    if risk:
                        risk_levels[risk] = risk_levels.get(risk, 0) + 1
                    
                    # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª—ã —Å –≤—ã—Å–æ–∫–∏–º —Ä–∏—Å–∫–æ–º
                    if risk == 'CRITICAL':
                        critical_files.append(result['filename'])
                    elif risk == 'HIGH':
                        high_risk_files.append(result['filename'])
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                    issues_list = []
                    
                    # –ò–∑ issues
                    issues = analysis.get('issues', [])
                    if isinstance(issues, list):
                        issues_list.extend([str(i) for i in issues if i])
                    elif isinstance(issues, str):
                        issues_list.append(issues)
                    
                    # –ò–∑ risk_analysis.key_risks
                    if not issues_list:
                        risk_analysis = analysis.get('risk_analysis', {})
                        if isinstance(risk_analysis, dict):
                            key_risks = risk_analysis.get('key_risks', [])
                            if isinstance(key_risks, list):
                                for risk in key_risks[:3]:
                                    if isinstance(risk, dict):
                                        risk_title = risk.get('title', '')
                                        if risk_title:
                                            issues_list.append(risk_title)
                                    elif isinstance(risk, str):
                                        issues_list.append(risk)
                    
                    # –ò–∑ risks
                    if not issues_list:
                        risks = analysis.get('risks', [])
                        if isinstance(risks, list):
                            issues_list.extend([str(r) for r in risks[:3] if r])
                        elif isinstance(risks, str):
                            issues_list.append(risks)
                    
                    all_issues.extend(issues_list[:3])  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 3 –ø—Ä–æ–±–ª–µ–º—ã
            
            # –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            processing_time = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
            if task.started_at and task.completed_at:
                try:
                    start = datetime.fromisoformat(task.started_at)
                    end = datetime.fromisoformat(task.completed_at)
                    delta = end - start
                    processing_time = f"{delta.total_seconds():.1f} —Å–µ–∫—É–Ω–¥"
                except:
                    pass
            
            # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç
            report_text = f"""
{'='*80}
–°–í–û–î–ù–´–ô –û–¢–ß–ï–¢ –ü–û –ü–ê–ö–ï–¢–ù–û–ô –û–ë–†–ê–ë–û–¢–ö–ï –î–û–ö–£–ú–ï–ù–¢–û–í
{'='*80}

–û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:
- –ù–∞–∑–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏: {task.task_name or f'–ó–∞–¥–∞—á–∞ #{task.id}'}
- ID –∑–∞–¥–∞—á–∏: {task.id}
- –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {task.created_at}
- –î–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: {task.completed_at}
- –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time}

{'='*80}
–°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò:
{'='*80}
- –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total}
- –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {completed}
- –û—à–∏–±–æ–∫: {failed}
- –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏: {success_rate}%

{'='*80}
–ê–ù–ê–õ–ò–ó –¢–ò–ü–û–í –î–û–ö–£–ú–ï–ù–¢–û–í:
{'='*80}
"""
            if doc_types:
                for doc_type, count in sorted(doc_types.items(), key=lambda x: x[1], reverse=True):
                    percentage = int((count / completed * 100)) if completed > 0 else 0
                    report_text += f"- {doc_type}: {count} ({percentage}%)\n"
            else:
                report_text += "- –¢–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã\n"
            
            report_text += f"\n{'='*80}\n–ê–ù–ê–õ–ò–ó –£–†–û–í–ù–ï–ô –†–ò–°–ö–ê:\n{'='*80}\n"
            risk_names = {
                'CRITICAL': '–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π',
                'HIGH': '–í—ã—Å–æ–∫–∏–π',
                'MEDIUM': '–°—Ä–µ–¥–Ω–∏–π',
                'LOW': '–ù–∏–∑–∫–∏–π',
                'INFO': '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π'
            }
            
            total_risks = sum(risk_levels.values())
            for risk, count in risk_levels.items():
                if count > 0:
                    percentage = int((count / total_risks * 100)) if total_risks > 0 else 0
                    report_text += f"- {risk_names.get(risk, risk)} ({risk}): {count} ({percentage}%)\n"
            
            # –ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤–æ—Å—Ç–∏
            high_risk_count = risk_levels.get('CRITICAL', 0) + risk_levels.get('HIGH', 0)
            if high_risk_count > 0:
                high_risk_percent = int((high_risk_count / total_risks * 100)) if total_risks > 0 else 0
                report_text += f"\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: {high_risk_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ({high_risk_percent}%) –∏–º–µ—é—Ç –≤—ã—Å–æ–∫–∏–π –∏–ª–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞!\n"
            
            # –°–≤–æ–¥–∫–∞ –ø–æ –ø—Ä–æ–±–ª–µ–º–∞–º
            if critical_files or high_risk_files:
                report_text += f"\n{'='*80}\n–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò –í–´–°–û–ö–û–†–ò–°–ö–û–í–ê–ù–ù–´–ï –î–û–ö–£–ú–ï–ù–¢–´:\n{'='*80}\n"
                if critical_files:
                    report_text += f"\nüî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –†–ò–°–ö ({len(critical_files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤):\n"
                    for filename in critical_files:
                        report_text += f"   - {filename}\n"
                if high_risk_files:
                    report_text += f"\nüü† –í–´–°–û–ö–ò–ô –†–ò–°–ö ({len(high_risk_files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤):\n"
                    for filename in high_risk_files:
                        report_text += f"   - {filename}\n"
            
            # –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
            if all_issues:
                report_text += f"\n{'='*80}\n–û–°–ù–û–í–ù–´–ï –ù–ê–ô–î–ï–ù–ù–´–ï –ü–†–û–ë–õ–ï–ú–´ –ò –†–ò–°–ö–ò:\n{'='*80}\n"
                unique_issues = list(dict.fromkeys(all_issues))[:10]  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ, –º–∞–∫—Å–∏–º—É–º 10
                for i, issue in enumerate(unique_issues, 1):
                    report_text += f"{i}. {issue}\n"
            
            report_text += f"\n{'='*80}\n–î–ï–¢–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û –ö–ê–ñ–î–û–ú–£ –î–û–ö–£–ú–ï–ù–¢–£:\n{'='*80}\n"
            for i, result in enumerate(results, 1):
                report_text += f"\n{i}. {result['filename']}\n"
                report_text += f"   {'-'*76}\n"
                if result.get('status') == 'completed':
                    analysis = result.get('analysis', {})
                    doc_type = analysis.get('document_type_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                    risk = analysis.get('risk_level', 'INFO')
                    risk_display = risk_names.get(risk, risk) if risk else '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω'
                    
                    report_text += f"   –°—Ç–∞—Ç—É—Å: ‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω\n"
                    report_text += f"   –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞: {doc_type}\n"
                    report_text += f"   –£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞: {risk_display} ({risk if risk else 'N/A'})\n"
                    
                    # –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ - –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–æ–ª–µ–π
                    summary = analysis.get('summary', '')
                    if not summary:
                        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ executive_summary
                        exec_summary = analysis.get('executive_summary', {})
                        if isinstance(exec_summary, dict):
                            summary = exec_summary.get('risk_description', '') or exec_summary.get('decision_support', '')
                    
                    if not summary:
                        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ expert_analysis
                        expert_analysis = analysis.get('expert_analysis', {})
                        if isinstance(expert_analysis, dict):
                            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –Ω–µ–ø—É—Å—Ç—É—é —Å–µ–∫—Ü–∏—é
                            for key in ['legal_expertise', 'financial_analysis', 'operational_risks', 'strategic_assessment']:
                                section_text = expert_analysis.get(key, '')
                                if section_text and len(section_text) > 20:
                                    summary = section_text
                                    break
                    
                    if summary:
                        summary_short = summary[:200] + '...' if len(summary) > 200 else summary
                        report_text += f"   –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ: {summary_short}\n"
                    
                    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã - –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ key_risks
                    issues = []
                    
                    # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–∑ issues
                    issues_raw = analysis.get('issues', [])
                    if issues_raw:
                        if isinstance(issues_raw, list):
                            issues = [str(item) for item in issues_raw if item]
                        elif isinstance(issues_raw, str):
                            issues = [issues_raw]
                    
                    # –ï—Å–ª–∏ issues –Ω–µ—Ç, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ risk_analysis.key_risks
                    if not issues:
                        risk_analysis = analysis.get('risk_analysis', {})
                        if isinstance(risk_analysis, dict):
                            key_risks = risk_analysis.get('key_risks', [])
                            if isinstance(key_risks, list):
                                for risk in key_risks[:3]:
                                    if isinstance(risk, dict):
                                        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É –∏–∑ —Ä–∏—Å–∫–∞
                                        risk_title = risk.get('title', '')
                                        risk_desc = risk.get('description', '')
                                        risk_level = risk.get('level', '')
                                        if risk_title:
                                            issue_text = f"{risk_level}: {risk_title}"
                                            if risk_desc:
                                                issue_text += f" - {risk_desc[:100]}"
                                            issues.append(issue_text)
                                    elif isinstance(risk, str):
                                        issues.append(risk)
                    
                    # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ—Ç, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ risks
                    if not issues:
                        risks = analysis.get('risks', [])
                        if isinstance(risks, list):
                            issues = [str(r) for r in risks[:3] if r]
                        elif isinstance(risks, str):
                            issues = [risks]
                    
                    if issues:
                        report_text += f"   –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:\n"
                        for issue in issues[:3]:
                            if issue and issue.strip():
                                report_text += f"      ‚Ä¢ {issue}\n"
                    
                    # –°—Å—ã–ª–∫–∞ –Ω–∞ –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
                    report_path = file_reports.get(result['filename'])
                    if report_path:
                        # –£–±–∏—Ä–∞–µ–º "static/reports/batch/" –∏–∑ –Ω–∞—á–∞–ª–∞ –ø—É—Ç–∏ –¥–ª—è URL
                        url_path = report_path
                        if url_path.startswith('static/reports/batch/'):
                            url_path = url_path.replace('static/reports/batch/', '')
                        elif url_path.startswith('reports/batch/'):
                            url_path = url_path.replace('reports/batch/', '')
                        elif url_path.startswith('static/'):
                            url_path = url_path.replace('static/', '')
                        
                        # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—ã–π URL –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
                        import os
                        base_url = os.getenv('BASE_URL', 'https://docscan-ai.ru')
                        # –£–±–∏—Ä–∞–µ–º —Å–ª—ç—à –≤ –∫–æ–Ω—Ü–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
                        base_url = base_url.rstrip('/')
                        
                        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—É—é —Å—Å—ã–ª–∫—É
                        full_url = f"{base_url}/batch-report/{url_path}"
                        report_text += f"   üìÑ –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç: {full_url}\n"
                else:
                    report_text += f"   –°—Ç–∞—Ç—É—Å: ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏\n"
                    report_text += f"   –û—à–∏–±–∫–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}\n"
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            report_text += f"\n{'='*80}\n–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:\n{'='*80}\n"
            if critical_files or high_risk_files:
                report_text += f"1. ‚ö†Ô∏è –û–±—Ä–∞—Ç–∏—Ç–µ –æ—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º –∏ –≤—ã—Å–æ–∫–∏–º —É—Ä–æ–≤–Ω–µ–º —Ä–∏—Å–∫–∞.\n"
                report_text += f"2. üìã –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–µ—Ç–∞–ª—å–Ω–æ –∏–∑—É—á–∏—Ç—å –ø–æ–ª–Ω—ã–µ –æ—Ç—á–µ—Ç—ã –ø–æ —ç—Ç–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º.\n"
                report_text += f"3. üîç –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –≤—ã—Å–æ–∫–∏–º —Ä–∏—Å–∫–æ–º.\n"
            else:
                report_text += f"1. ‚úÖ –í—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–º–µ—é—Ç –ø—Ä–∏–µ–º–ª–µ–º—ã–π —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞.\n"
                report_text += f"2. üìã –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è —Å –ø–æ–ª–Ω—ã–º–∏ –æ—Ç—á–µ—Ç–∞–º–∏ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.\n"
            
            if failed > 0:
                report_text += f"4. üîß –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª—ã —Å –æ—à–∏–±–∫–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏—Ö –ø–æ–≤—Ç–æ—Ä–Ω–æ.\n"
            
            report_text += f"\n{'='*80}\n"
            report_text += f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {datetime.now().isoformat()}\n"
            report_text += f"{'='*80}\n"
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –≤ —Ñ–∞–π–ª
            reports_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'static', 'reports', 'batch')
            os.makedirs(reports_dir, exist_ok=True)
            
            report_path = os.path.join(reports_dir, f'batch_task_{task_id}_report.txt')
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_text)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–¥–∞—á—É
            task.summary_report_path = f'static/reports/batch/batch_task_{task_id}_report.txt'
            db.session.commit()
            
            logger.info(f"‚úÖ –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {report_path}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {e}")
    
    @staticmethod
    def get_task_status(task_id):
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏"""
        try:
            task = BatchProcessingTask.query.get(task_id)
            if not task:
                return None, "–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
            return task.to_dict(), None
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏: {e}")
            return None, str(e)
    
    @staticmethod
    def get_user_tasks(user_id, limit=20):
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            tasks = BatchProcessingTask.query.filter_by(user_id=user_id).order_by(
                BatchProcessingTask.created_at.desc()
            ).limit(limit).all()
            return [task.to_dict() for task in tasks]
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–¥–∞—á –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
            return []
    
    @staticmethod
    def get_task_files(task_id):
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã –∑–∞–¥–∞—á–∏"""
        try:
            files = BatchProcessingFile.query.filter_by(task_id=task_id).order_by(
                BatchProcessingFile.created_at.asc()
            ).all()
            return [f.to_dict() for f in files]
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –∑–∞–¥–∞—á–∏: {e}")
            return []

